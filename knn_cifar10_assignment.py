#!/usr/bin/env python3
# -*- coding: utf-8 -*-

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
K-Nearest Neighbors (KNN) on CIFAR-10 â€” Assignment Version
----------------------------------------------------------
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” CIFAR-10 ë°ì´í„°ì…‹ì— ëŒ€í•´ KNN ë¶„ë¥˜ê¸°ë¥¼ ì ìš©í•˜ê³ ,
ë‹¤ìŒì˜ ì„¸ ê°€ì§€ ì‹¤í—˜ ëª¨ë“œë¥¼ ì§€ì›í•œë‹¤.

[ì²´í¬ë¦¬ìŠ¤íŠ¸ âœ…]
1) CIFAR-10 ë°ì´í„°ì…‹ (torchvision)
2) KNN ë¶„ë¥˜ (scikit-learn)
3) ì‹¤í—˜ ëª¨ë“œ
   - split      : train/test ë¶„í• 
   - split_val  : train/validation/test (valë¡œ best-k ì„ íƒ)
   - cv         : 5-fold êµì°¨ê²€ì¦
4) í‰ê°€ì§€í‘œ: accuracy, precision, recall, F1(macro)
5) k-ìŠ¤ìœ• ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥ (í•„ìš” ì‹œ save_plot_k_sweep ì‚¬ìš©)

[ì‹¤í–‰ ì˜ˆì‹œ]
# 1) ë‹¨ìˆœ train/test (k=5ë§Œ ê²€ì‚¬)
python knn_cifar10_assignment.py --mode split --k_list 5 --train_size 10000 --test_size 5000

# 2) train/val/test (valë¡œ best-k ì„ íƒ)
python knn_cifar10_assignment.py --mode split_val --k_list 1 3 5 7 9 \
  --train_size 10000 --val_size 5000 --test_size 5000

# 3) 5-fold êµì°¨ê²€ì¦ (k-ìŠ¤ìœ•)
python knn_cifar10_assignment.py --mode cv --k_list 1 3 5 7 9 --folds 5
"""


import argparse
import numpy as np
import torch
from torchvision import datasets, transforms
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt

def save_plot_k_sweep(rows, title, out):
    """k-ìŠ¤ìœ• ê²°ê³¼ë¥¼ ì„  ê·¸ë˜í”„ë¡œ ì €ì¥
    - rows: [{"k": int, "accuracy": float, ...}, ...] í˜•íƒœ ê°€ì •
    - title: ê·¸ë¦¼ ì œëª©
    - out: ì €ì¥ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: 'plot_split_k.png')
    [ì‚¬ìš© ì˜ˆì‹œ]
      rows = [{"k":1,"accuracy":0.45}, {"k":3,"accuracy":0.50}, ...]
      save_plot_k_sweep(rows, "Simple Split Accuracy vs k", "plot_split_k.png")
    """
    ks = [r["k"] for r in rows]
    accs = [r["accuracy"] for r in rows]
    plt.figure(figsize=(6,4))
    plt.plot(ks, accs, "-o")
    plt.title(title)
    plt.xlabel("k")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(out)
    print(f"[Saved plot] {out}")

def run_kfold_cv(X, y, k_list, n_splits=5, random_state=42, use_scaler=True):
    """
    StratifiedKFold êµì°¨ê²€ì¦
    - ê° í´ë“œì—ì„œ train/testë¥¼ ë°˜ë³µí•˜ë©° kë³„ ì„±ëŠ¥ ì¸¡ì •
    - foldë³„ í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚° í›„ ê·¸ë˜í”„ë¡œ ì €ì¥ (plot_cv_k.png)
    """
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    results = {k: [] for k in k_list}

    # fold ë°˜ë³µ
    for fold, (tr_idx, te_idx) in enumerate(skf.split(X, y), 1):
        print(f"\n[CV] Fold {fold}/{n_splits}")
        X_tr, X_te = X[tr_idx], X[te_idx]
        y_tr, y_te = y[tr_idx], y[te_idx]

        # ê° foldì—ì„œ scalerëŠ” ìƒˆë¡œ í•™ìŠµí•´ì•¼ í•¨ (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
        X_tr_f, meta = build_features(X_tr, use_scaler=use_scaler)
        X_te_f = meta["scaler"].transform(X_te) if "scaler" in meta else X_te

        # k ìŠ¤ìœ•
        for k in k_list:
            clf = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)
            clf.fit(X_tr_f, y_tr)
            y_pred = clf.predict(X_te_f)
            metrics = evaluate(y_te, y_pred)
            results[k].append(metrics["accuracy"])
            print(f"k={k} â†’ acc={metrics['accuracy']:.4f}, f1={metrics['f1']:.4f}")

    # í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    summary_rows = []
    print("\n[CV Summary] mean Â± std")
    for k in k_list:
        accs = np.array(results[k])
        mean, std = accs.mean(), accs.std(ddof=1)
        summary_rows.append({"k": k, "accuracy_mean": mean, "accuracy_std": std})
        print(f"k={k}: {mean:.4f} Â± {std:.4f}")

    # ê·¸ë˜í”„ ì €ì¥ (error bar í¬í•¨)
    plt.figure(figsize=(7, 5))
    ks = [r["k"] for r in summary_rows]
    acc_mean = [r["accuracy_mean"] for r in summary_rows]
    acc_std = [r["accuracy_std"] for r in summary_rows]

    plt.errorbar(ks, acc_mean, yerr=acc_std, fmt="-o", capsize=5)
    plt.title(f"{n_splits}-Fold CV: Accuracy vs k (Â±std)")
    plt.xlabel("k")
    plt.ylabel("Accuracy")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig("plot_cv_k.png")
    print("[Saved plot] plot_cv_k.png")

def run_split_with_val(X, y, k_list, val_size, test_size, random_state=42, use_scaler=True):
    # 1) ë¨¼ì € testë¥¼ ë¶„ë¦¬ â†’ ë‚¨ì€ ë°ì´í„°ì—ì„œ train/val ë¶„ë¦¬
    X_tmp, X_te, y_tmp, y_te = train_test_split(
        X, y, test_size=test_size, stratify=y, random_state=random_state
    )
    val_ratio = val_size / len(X_tmp)
    X_tr, X_val, y_tr, y_val = train_test_split(
        X_tmp, y_tmp, test_size=val_ratio, stratify=y_tmp, random_state=random_state
    )

    # 2) ì „ì²˜ë¦¬ fitì€ trainìœ¼ë¡œë§Œ â†’ val/testì—ëŠ” transformë§Œ (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
    X_tr_f, meta = build_features(X_tr, use_scaler=use_scaler)
    X_val_f = meta["scaler"].transform(X_val) if "scaler" in meta else X_val
    X_te_f  = meta["scaler"].transform(X_te)  if "scaler" in meta else X_te

    # 3) ê²€ì¦ì…‹ìœ¼ë¡œ ê° k ì„±ëŠ¥ ì¸¡ì • (â†’ í”Œë¡¯ì— ì“¸ rows ë§Œë“¤ì–´ë‘ê¸°) (ì—¬ê¸°ì„  macro-F1 ê¸°ì¤€)
    val_scores = []
    best_k, best_f1 = None, -1.0
    for k in k_list:
        clf = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)
        clf.fit(X_tr_f, y_tr)
        val_pred = clf.predict(X_val_f)
        metrics = evaluate(y_val, val_pred)
        val_scores.append({"k": k, **metrics})
        if metrics["f1"] > best_f1:
            best_k, best_f1 = k, metrics["f1"]

    # 4) best-kë¡œ ì¬í•™ìŠµ í›„ test í‰ê°€
    clf = KNeighborsClassifier(n_neighbors=best_k, n_jobs=-1)
    clf.fit(X_tr_f, y_tr)
    test_pred = clf.predict(X_te_f)
    print(f"[Best k={best_k}] Test â†’ {evaluate(y_te, test_pred)}")

    # 5) ê²€ì¦ ì„±ëŠ¥ ê·¸ë˜í”„ ì €ì¥
    save_plot_k_sweep(val_scores, title="Validation Performance vs k", out="plot_val_k.png")

def run_simple_split(X, y, k_list, test_size, random_state=42, use_scaler=True):
    # 1) Stratified split: í´ë˜ìŠ¤ ë¹„ìœ¨ ë³´ì¡´
    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=test_size, stratify=y, random_state=random_state
    )

    # 2) ì „ì²˜ë¦¬(í•™ìŠµì…‹ ê¸°ì¤€ìœ¼ë¡œ fit) â†’ í…ŒìŠ¤íŠ¸ì…‹ì—ëŠ” transformë§Œ ì ìš© (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
    X_tr_f, meta = build_features(X_tr, use_scaler=use_scaler)
    X_te_f = meta["scaler"].transform(X_te) if "scaler" in meta else X_te

    # 3) ì—¬ëŸ¬ k ìŠ¤ìœ•: í•™ìŠµâ†’ì˜ˆì¸¡â†’ì§€í‘œ ì¶œë ¥
    print("[Simple Split] Train:", X_tr_f.shape, "Test:", X_te_f.shape)
    results = []  # ğŸ‘ˆ ê·¸ë˜í”„ìš© ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
    for k in k_list:
        clf = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)
        clf.fit(X_tr_f, y_tr)
        y_pred = clf.predict(X_te_f)
        metrics = evaluate(y_te, y_pred)
        results.append({"k": k, **metrics})
        print(f"k={k} â†’ {metrics}")

    # 4) ê²°ê³¼ ìš”ì•½ + ê·¸ë˜í”„ ì €ì¥
    print("\n[Simple Split Summary]")
    for row in results:
        print(row)

    save_plot_k_sweep(results, title="Simple Split: Test Accuracy vs k", out="plot_split_k.png")


def evaluate(y_true, y_pred):
    """í‰ê°€ì§€í‘œ ê³„ì‚°
    - accuracy: ì „ì²´ ì •í™•ë„
    - precision/recall/F1: macro-average (í´ë˜ìŠ¤ ë¶ˆê· í˜• ì˜í–¥ ì™„í™”)
    - zero_division=0: íŠ¹ì • í´ë˜ìŠ¤ ë¯¸ì˜ˆì¸¡ ì‹œ division by zero ë°©ì§€
    """
    acc = accuracy_score(y_true, y_pred)
    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average="macro", zero_division=0)
    return {"accuracy": acc, "precision": prec, "recall": rec, "f1": f1}

def build_features(X, use_scaler=True):
    """íŠ¹ì§• ì „ì²˜ë¦¬ (KNN ìµœì í™”)
    - KNNì€ 'ê±°ë¦¬' ê¸°ë°˜ â†’ ê° ì°¨ì›ì˜ ìŠ¤ì¼€ì¼(ë¶„ì‚°)ì´ ë‹¤ë¥´ë©´ ì™œê³¡ ë°œìƒ
    - StandardScaler: í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ì •ê·œí™”í•˜ì—¬ ê±°ë¦¬ ê³„ì‚°ì„ ì•ˆì •í™”
    """
    if use_scaler:
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        return X, {"scaler": scaler}
    return X, {}

def load_cifar10(root="./data", train=True):
    """CIFAR-10ì„ torchvisionì—ì„œ ë¶ˆëŸ¬ì˜¨ë‹¤.
    - transform: ToTensor() â†’ Tensor(C,H,W) in [0,1] ë²”ìœ„
    - train=True  : 50,000ì¥ (í´ë˜ìŠ¤ë³„ 5,000ì¥)
    - train=False : 10,000ì¥ (ì—¬ê¸°ì„œëŠ” ì§ì ‘ ë¶„í• ì„ í•˜ë¯€ë¡œ ì£¼ë¡œ train=True ì‚¬ìš©)
    """
    tfm = transforms.Compose([transforms.ToTensor()])
    ds = datasets.CIFAR10(root=root, train=train, download=True, transform=tfm)
    return ds

def dataset_to_numpy(ds, max_samples=None):
    """torch Dataset â†’ numpy ë°°ì—´
    - ê³ ì „ì ì¸ KNN(ê±°ë¦¬ê¸°ë°˜) ì‹¤í—˜ì„ ìœ„í•´ í”½ì…€ì„ í‰íƒ„í™”(flatten)í•˜ì—¬ ì‚¬ìš© (3072ì°¨ì›)
    - max_samples: ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•œ ìƒí•œ
    ë°˜í™˜:
      X: (N, 3072) float32, y: (N,) int64
    """
    if max_samples is None:
        max_samples = len(ds)
    idxs = np.arange(len(ds))[:max_samples]
    Xs, ys = [], []
    for i in idxs:
        img, label = ds[i]
        Xs.append(img.numpy().reshape(-1))
        ys.append(label)
    X = np.stack(Xs).astype(np.float32)
    y = np.array(ys, dtype=np.int64)
    return X, y

def main():
    parser = argparse.ArgumentParser(description="KNN on CIFAR-10 (Assignment)")
    parser.add_argument("--mode", choices=["split","split_val","cv"], required=True)
    parser.add_argument("--train_size", type=int, default=10000)
    parser.add_argument("--val_size", type=int, default=5000)
    parser.add_argument("--test_size", type=int, default=5000)
    parser.add_argument("--k_list", type=int, nargs="+", default=[1,3,5,7,9])
    parser.add_argument("--folds", type=int, default=5)
    parser.add_argument("--data_root", type=str, default="./data")
    args = parser.parse_args()

    ds = load_cifar10(args.data_root, train=True)
    X, y = dataset_to_numpy(ds, max_samples=args.train_size + args.val_size + args.test_size)
    if args.mode == "split":
        run_simple_split(X, y, args.k_list, args.test_size)
    elif args.mode == "split_val":
        run_split_with_val(X, y, args.k_list, args.val_size, args.test_size)
    elif args.mode == "cv":
        run_kfold_cv(X, y, args.k_list, args.folds)


if __name__ == "__main__":
    main()
